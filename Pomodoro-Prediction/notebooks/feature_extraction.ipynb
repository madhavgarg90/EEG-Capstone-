{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import skew, kurtosis as kurt, entropy as entr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 128 # sample rate (Hz)\n",
    "bins = 10 # entropy calculation\n",
    "folder_path = Path(\"..\")/\"eeg_emotion_data\" # folder containing .dat file for each participant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load one participant file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    file_path = Path(file_path) # ensure it is a path object\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with file_path.open(\"rb\") as f:\n",
    "            participant_data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "        # extract first 32 channels out of 40 and remove 3-sec pre-trial baseline from each channel\n",
    "        eeg_data = participant_data[\"data\"][:, :32, 3*sf:] # shape (40, 32, 63*sf - 3*sf) = (trials, channels, sample values)\n",
    "        labels = participant_data[\"labels\"][:, :2] # shape (40, 2) = (trials, [valence arousal])\n",
    "\n",
    "        return eeg_data, labels\n",
    "    \n",
    "    except (pickle.UnpicklingError, EOFError) as e:\n",
    "        print(f\"❌ Error loading pickle file: {file_path} -> {e}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error while loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to divide trials of one participant into 10-sec windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for creating 7680x321 shaped dataset\n",
    "\n",
    "# for one participant,\n",
    "    # rows = trials * no. of windows per trial (40 * 6) [each trial is of one minute]\n",
    "\n",
    "def windowing(eeg_data, labels):\n",
    "    new_eeg_data = []\n",
    "    new_labels = []\n",
    "\n",
    "    for trial, label_row in zip(eeg_data, labels):\n",
    "        for i in range(0, 6):\n",
    "            window = trial[:, (10*i)*sf:(10*(i + 1))*sf] # shape (32, 5*sf)\n",
    "            new_eeg_data.append(window)\n",
    "            new_labels.append(label_row)\n",
    "\n",
    "    return np.array(new_eeg_data), np.array(new_labels) # shape (240, 32, 5*sf), shape (240, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare labels for target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_focus_level(valence, arousal):\n",
    "    if valence >= 4.5 and arousal >= 4.5: # highly focused\n",
    "        return 1\n",
    "    else: # distracted\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(labels):\n",
    "    focus_label = np.array([calculate_focus_level(v, a) for v, a in labels])\n",
    "\n",
    "    return focus_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to extract bandpower and statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bandpower(eeg_channel_arr, band_name):\n",
    "    bands = {\n",
    "        \"theta\": (4, 8),\n",
    "        \"alpha\": (8, 12),\n",
    "        \"beta\": (12, 30),\n",
    "        \"gamma\": (30, 45)\n",
    "    }\n",
    "\n",
    "    range = bands[band_name]\n",
    "\n",
    "    # get array of freqs and corresponding power values\n",
    "    freqs, psd = welch(eeg_channel_arr, sf, nperseg=256)\n",
    "    \n",
    "    # choose freqs within the freq range\n",
    "    valid_indices = np.logical_and(freqs >= range[0], freqs < range[1])\n",
    "\n",
    "    # calculate mean of all the power values for one channel\n",
    "    return np.mean(psd[valid_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat_features(eeg_channel_arr):\n",
    "    mean = np.mean(eeg_channel_arr)\n",
    "    std = np.std(eeg_channel_arr)\n",
    "    skewness = skew(eeg_channel_arr)\n",
    "    kurtosis = kurt(eeg_channel_arr)\n",
    "\n",
    "    hist, _ = np.histogram(eeg_channel_arr, bins=bins, density=True)\n",
    "    entropy = entr(hist)\n",
    "\n",
    "    return mean, std, skewness, kurtosis, entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create feature matrix for one participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(eeg_data):\n",
    "    feature_matrix = []\n",
    "\n",
    "    for trial in eeg_data:\n",
    "        trial_features = []\n",
    "\n",
    "        for channel in trial:\n",
    "            theta = compute_bandpower(channel, \"theta\")\n",
    "            alpha = compute_bandpower(channel, \"alpha\")\n",
    "            beta = compute_bandpower(channel, \"beta\")\n",
    "            gamma = compute_bandpower(channel, \"gamma\")\n",
    "\n",
    "            beta_alpha_ratio = beta/alpha\n",
    "\n",
    "            mean, std, skewness, kurtosis, entropy = compute_stat_features(channel)\n",
    "\n",
    "            channel_features = [theta, alpha, beta, gamma, beta_alpha_ratio, mean, std, skewness, kurtosis, entropy]\n",
    "\n",
    "            trial_features.extend(channel_features)\n",
    "\n",
    "        feature_matrix.append(trial_features)\n",
    "\n",
    "    return np.array(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a single featre matrix for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_matrix(folder_path, windowing_used):\n",
    "    feature_matrix, focus_label = [], []\n",
    "\n",
    "    for participant_file in folder_path.iterdir():\n",
    "        eeg_data, labels = load_file(participant_file)\n",
    "\n",
    "        if eeg_data is None or labels is None:\n",
    "            print(f\"⚠️ Skipping {participant_file}: Failed to load data\")\n",
    "            continue\n",
    "\n",
    "        if windowing_used == True:\n",
    "            eeg_data, labels = windowing(eeg_data, labels)\n",
    "\n",
    "        focus_label.extend(prepare_labels(labels).tolist())\n",
    "\n",
    "        feature_matrix.append(create_feature_matrix(eeg_data)) # creates list of matrices\n",
    "\n",
    "    feature_matrix = np.concatenate(feature_matrix, axis=0) # list of matrices to ndarray\n",
    "    focus_label = np.array(focus_label).reshape(-1, 1) # convert labels into a column vector\n",
    "\n",
    "    return np.hstack((feature_matrix, focus_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save the final matrix as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mat_as_df(matrix, path):\n",
    "    features = [\"Theta\", \"Alpha\", \"Beta\", \"Gamma\", \"BetaAlpha\", \"Mean\", \"Std\", \"Skew\", \"Kurt\", \"Entropy\"]\n",
    "\n",
    "    column_names = [f\"{feature}_{i+1}\" for i in range(32) for feature in features]\n",
    "    column_names.append(\"Focus_Level\")\n",
    "\n",
    "    df = pd.DataFrame(matrix, columns=column_names)\n",
    "    df.to_excel(path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataset with each trial as a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = final_matrix(folder_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "feature_matrix[:, :-1] = scalar.fit_transform(feature_matrix[:, :-1]) # exclude the target variable\n",
    "joblib.dump(scalar, '../models/scalar_1d.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the matrix as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../1280x321.xlsx\"\n",
    "df = save_mat_as_df(feature_matrix, path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a dataset with each 10-sec window as a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = final_matrix(folder_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "feature_matrix[:, :-1] = scalar.fit_transform(feature_matrix[:, :-1]) # exclude the target variable\n",
    "joblib.dump(scalar, '../models/scalar_2d.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the matrix as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../7680x321.xlsx\"\n",
    "df = save_mat_as_df(feature_matrix, path)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
